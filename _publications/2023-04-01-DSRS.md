---
title: "Deep Shape Representation with Sharp Feature Preservation"
collection: publications
permalink: /publication/2023-04-01-DSRS
excerpt: 'We present a novel implicit neural representation to reconstruct CAD models from point clouds with high quality. Our method first extracts edge points from input points by an edge detection network and then recovers implicit surfaces while preserving the sharp features of ground-truth models. The edge detection network uses a U-Net structure for feature encoding, and the attention module is introduced to improve the accuracy in the CAD models. This detection network is light weighted and runs fast. Afterward, we propose an MLP-based network to train an implicit representation from input points with its extracted edge points. A two-stage training process is proposed, and loss functions are designed for each stage to ensure that the sharp features of the input points are learned while the surface details are fitted. Comparing our method with other SOTA methods in the ABC dataset, our method is significantly superior to the existing nonlearning and learning 3D reconstruction methods in terms of surface approximation quality and sharp feature preservation. Moreover, we can gain spline representations from learned shapes for CAM as the application of our method.'
date: 2023-04-01
venue: 'CAD'
paperurl: 'https://www.sciencedirect.com/science/article/pii/S0010448522002019'
citation: 'Feng Y F, Shen L Y, Yuan C M, et al. Deep Shape Representation with Sharp Feature Preservation[J]. Computer-Aided Design, 2023: 103468.'
---
We present a novel implicit neural representation to reconstruct CAD models from point clouds with high quality. Our method first extracts edge points from input points by an edge detection network and then recovers implicit surfaces while preserving the sharp features of ground-truth models. The edge detection network uses a U-Net structure for feature encoding, and the attention module is introduced to improve the accuracy in the CAD models. This detection network is light weighted and runs fast. Afterward, we propose an MLP-based network to train an implicit representation from input points with its extracted edge points. A two-stage training process is proposed, and loss functions are designed for each stage to ensure that the sharp features of the input points are learned while the surface details are fitted. Comparing our method with other SOTA methods in the ABC dataset, our method is significantly superior to the existing nonlearning and learning 3D reconstruction methods in terms of surface approximation quality and sharp feature preservation. Moreover, we can gain spline representations from learned shapes for CAM as the application of our method.

[Download paper here](https://www.sciencedirect.com/science/article/pii/S0010448522002019)

Recommended citation: Feng Y F, Shen L Y, Yuan C M, et al. Deep Shape Representation with Sharp Feature Preservation[J]. Computer-Aided Design, 2023: 103468.
